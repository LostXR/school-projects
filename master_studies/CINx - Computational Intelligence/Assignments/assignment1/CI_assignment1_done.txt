1. How do you think adaptation and self-organization are interrelated? (OK)

	Complex adaptive systems often exhibits some aspects of self-organization. Terms self-adaptation and self-organization are often used with a description of some more complex system which is based on Computational Intelligence, which means that they are interrelated and according to the definition of CI system, a one must have both of those abilities. Only together they can make predictions, decisions, generalizations and reason in complex and changing environments. Adaptation is necessary for surviving and improvements and that is necessary for evolution (natural selection + self-organization).



2. What is the difference between fuzziness and probability? Provide an example to illustrate the difference. (OK)
	
	Fuzziness is a superset of probability. Fuziness says that something happens with some degree, it's not just a certainty that some event occur in a number between 0 and 1. Probability is valid just for future/unknown events (then after the event is observed it is gone) and fuzzy set membership continues after the event. Probability - enclosed world model, everything is known. Fuzzy logic - we don't assume that everything is known, it is not based on enclosed world model. Probability requires independency of variables and fuzzy logic doesn't. 

	Probability - the weather forecasting measurement and predictions done by computers and other machines
	Fuzziness - the weather measurement at a given moment done by human - "it is cold, warm, ..."



3. What is the definition of artificial intelligence? List some differences between
computational intelligence and artificial intelligence. (OK)

	Artificial intelligence is defined as the study of the computation required for intelligent behavior (mostly humans, but also animals and so on) and the attempt to duplicate such computation using computers. It is based on rules. 

	With comparison to computational intelligence, AI doesn't have the ability to generalize and perform well in complex and changing environments. It also cannot deal with partial truths and uncertainty.



4. Give a real-world example of each type of adaptation: supervised, reinforcement, and unsupervised. (OK)
	
	Supervised - distinguishing between apple and granade if the system has on its input pictures of both and knows what is what because such data are labeled
	Reinforcement - player decisions (good or bad) in playing games or Particle Swarm Optimization
	Unsupervised - clustering, for example K-means used on market prices



5. Convert the following binary coded strings to Gray coding: 10111010, 10010100, 01101110. (OK)

	10111010 to grey = 11100111
	10010100 to grey = 11011110
	01101110 to grey = 01011001


6. Calculate  two generations for the simple  problem max {x2} over x {0,.. 63} 
	a) Starting with random numbers  {0.3, 0.6, 0.1, 0.7}  calculate the binary representation of the code to be used with initial population of 4.
		for 0.3: 19 - 010011
		for 0.6: 38 - 100110
		for 0.1:  6 - 000110
		for 0.7: 44 - 101100

	b) For each member of the initial population calculate x, f(x), fnorm, cumulative  fnorm,
		bin		x		f(x)	fnorm	cumulative fnorm
		010011	19		361		0.096	0.096
		100110  38		1444	0.382	0.478
		000110	6		36		0.010	0.488
		101100	44		1936	0.513	1.000
					Ef(x)=3777

	c) Using roulette wheel selection with random numbers {0.3, 0.8, 0,2, 0.5} form the population after reproduction with 4 spins.
		38
		44
		38
		44

	d) Perform a two point crossover between individuals 1,2 {crossover 3,5 bits} and individuals 3,4 {crossover 5,2 bits}
		mem 1: 	100110 -> 100100  (36)
		mem 2:	101100 -> 101110  (46)
		mem 3:	100110 -> 101110  (46)
		mem 4:	101100 -> 100100  (36)

	e) Perform bitwise mutation on 3rd bit from left of 2nd individual and 5th bit from left on 4th individual.
		mem 1: 	100100
		mem 2:	100110
		mem 3:	101110
		mem 4:	100110

	f) Repeat step b, 
		bin		x		f(x)	fnorm	cumulative fnorm
		100100	36		1296	0.206		0.206
		100110  38		1444	0.229		0.435
		101110	46		2116	0.336		0.771
		100110	38	 	1444	0.229		1.000
						Ef(x)=6300

	g) Repeat step c with random numbers {0.1, 0.3, 0,9, 0.7}  
		100100	36
		100110  38
		100110	38
		101110	46

	h) Perform a one point crossover between individuals 1,3 {crossover 3rd bit} and individuals 2,4 {crossover 4th bit}
		100110 	38
		101110	46
		100100	36
		100110	38

	i) Repeat step b
		bin		x		f(x)	fnorm	cumulative fnorm
		100110	38		1444	0.229	0.229
		101110	46		2116	0.336	0.565
		100100	36		1296	0.206	0.771
		100110  38		1444	0.229	1.000
						Ef(x)=6300

	j) Using modified roulette wheel selection (Baker) with random number {0.4}  form the third generation population after reproduction with 1 spin.
		101110	- decimal number 46


7. After running a genetic algorithm for a fairly long time, the fitness values tend to cluster at the high end of the scale. For example, on a scale of 0 to 1, they might cluster from 0.90 to 0.98. What is the main problem with this? How can it be alleviated? (OK)

	The main problem is that the calculation is stuck on local minima. 

	It can be solved by equally spacing fitness values or use scaling window over last few generations that keeps track of minimum fitness value. ????

	It can be also worth to try different operations, rates or parameters during reproduction (forming new population) process - like mutation rate (number of bites being mutated) etc. for mitigation.


8. What is the main difference between evolutionary programming and evolution
strategies? (OK)

	The population in EP is a vector of solutions (programs) and the population in ES is a vector of real values.

	They use different operations - EP uses mutation only (so not crossover) and ES uses recombination (similar to crossover) and (Gaussian) mutation. 

	EP generates the same number of children as parents and ES have usually more children than parrents (it is often about 7 times more).



9. What are the main difference between genetic algorithms and genetic programming? (OK)

	Population members (programs) in GP are represented as tree structures and they may vary in size and complexity. In GA there are strings of bits and/or variables as population members. 

	In GP the fitness is measured by executing individual population member (often more times, let's say 100 times and then calculate the average value) and fitness measurement in GA depend on a particular problem (but often just 1 measurement for each member). 



10. For each of the schemata 0**1**11, 001***1*, *1*10*1* and **1**01* give the order o(H) and the defining length δ(H). (OK)

	0**1**11 - o(H) = 4, δ(H)= 7
	001***1* - o(H) = 4, δ(H)= 6
	*1*10*1* - o(H) = 4, δ(H)= 5
	**1**01* - o(H) = 3, δ(H)= 4
